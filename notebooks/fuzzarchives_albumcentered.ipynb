{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Fuzz Archives: Album-Centered Graph\n\n*Powered by **Traverse** and Visualized with **Cosmograph***\n\nBuild a similarity graph where **each node is a record/album** and edges\nconnect records that share genre/style tags.  The more tags two records\nshare, the stronger the link.\n\nThis is the inverse of the tag co-occurrence graph (where nodes are tags\nand links represent shared albums).\n\n**Prerequisites:**\n```bash\npip install -e \".[dev]\"\ncd src/traverse/cosmograph/app && npm install && npm run build\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\nRECORDS_CSV = Path(r\"C:\\Users\\xtrem\\Documents\\Datasets\\records.csv\")\nOUT_DIR = Path(\"_out_album\")\nFORCE = False  # set True to rebuild cache\n\n# Tuning parameters\nMIN_WEIGHT = 2              # min shared tags to create an edge\nMAX_NODES = 0               # 0 = unlimited (all records with edges)\nMAX_EDGES = 0               # 0 = unlimited\nMAX_TAG_DEGREE = 500        # sample/skip tags shared by more records than this\nSAMPLE_HIGH_DEGREE = True   # True = sample down; False = skip entirely\nUNWEIGHTED = False          # True = pure connectivity (no weights, faster, less memory)\nMAX_EDGE_WEIGHT = 0         # cap edge weights at this value; 0 = unlimited"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Build or Load Graph\n",
    "\n",
    "Build the album-centered similarity graph from the records CSV (or load\n",
    "from cache).  Uses a separate `_out_album/` cache dir to avoid colliding\n",
    "with the tag co-occurrence cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "from traverse.graph.album_graph import build_album_graph\nfrom traverse.graph.cache import GraphCache\n\ncache = GraphCache(\n    cache_dir=OUT_DIR,\n    build_fn=lambda: build_album_graph(\n        RECORDS_CSV,\n        min_weight=MIN_WEIGHT,\n        max_nodes=MAX_NODES,\n        max_edges=MAX_EDGES,\n        max_tag_degree=MAX_TAG_DEGREE,\n        sample_high_degree=SAMPLE_HIGH_DEGREE,\n        unweighted=UNWEIGHTED,\n        max_edge_weight=MAX_EDGE_WEIGHT,\n    ),\n    force=FORCE,\n)\ngraph, records_df = cache.load_or_build()\nprint(f\"Graph: {len(graph['points'])} nodes, {len(graph['links'])} edges\")\nprint(f\"Records: {len(records_df):,} rows\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Community Detection\n",
    "\n",
    "Run Louvain community detection and add community labels to each album node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 communities:\n",
      "  Community 0: 48 nodes\n",
      "  Community 1: 35 nodes\n",
      "  Community 2: 20 nodes\n",
      "  Community 3: 19 nodes\n",
      "  Community 4: 12 nodes\n",
      "  Community 5: 10 nodes\n",
      "  Community 6: 8 nodes\n",
      "  Community 7: 7 nodes\n",
      "  Community 8: 6 nodes\n",
      "  Community 9: 5 nodes\n",
      "  Community 10: 5 nodes\n",
      "  Community 11: 5 nodes\n",
      "  Community 13: 4 nodes\n",
      "  Community 12: 4 nodes\n",
      "  Community 15: 3 nodes\n",
      "  Community 14: 3 nodes\n",
      "  Community 16: 3 nodes\n",
      "  Community 18: 2 nodes\n",
      "  Community 17: 2 nodes\n",
      "  Community 19: 2 nodes\n",
      "  Community 20: 2 nodes\n",
      "  Community 21: 2 nodes\n",
      "  Community 22: 2 nodes\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from traverse.graph.community import add_communities, CommunityAlgorithm\n",
    "\n",
    "graph = add_communities(graph, CommunityAlgorithm.LOUVAIN, seed=42)\n",
    "\n",
    "comm_counts = Counter(pt[\"community\"] for pt in graph[\"points\"])\n",
    "print(f\"{len(comm_counts)} communities:\")\n",
    "for comm_id, count in comm_counts.most_common():\n",
    "    print(f\"  Community {comm_id}: {count} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Sanity Check\n",
    "\n",
    "Sample a node and its neighbors to verify the graph makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "import random\n\nsample_pt = random.choice(graph[\"points\"])\nsample_id = sample_pt[\"id\"]\nprint(f\"Sample node: {sample_pt}\")\nprint()\n\n# Find neighbors\nid_to_pt = {pt[\"id\"]: pt for pt in graph[\"points\"]}\nneighbors = []\nfor lk in graph[\"links\"]:\n    w = lk.get(\"weight\", 1)\n    if lk[\"source\"] == sample_id:\n        neighbors.append((lk[\"target\"], w))\n    elif lk[\"target\"] == sample_id:\n        neighbors.append((lk[\"source\"], w))\n\nneighbors.sort(key=lambda x: x[1], reverse=True)\nprint(f\"{len(neighbors)} neighbors (top 10 by shared tags):\")\nfor nid, w in neighbors[:10]:\n    npt = id_to_pt.get(nid, {})\n    print(f\"  w={w}: {npt.get('label', nid)} — {npt.get('artist', '?')}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 5. Export & Serve\n",
    "\n",
    "Export the community graph JSON and start the Cosmograph server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "from traverse.graph.adapters_cosmograph import CosmographAdapter\nfrom traverse.cosmograph.server import serve, _default_dist_dir\n\nn_pts = len(graph[\"points\"])\nn_lks = len(graph[\"links\"])\nprint(f\"Graph: {n_pts:,} nodes, {n_lks:,} edges\")\n\n# Browser safety check — Cosmograph handles ~500K edges max in-browser\nif n_lks > 500_000:\n    print(f\"WARNING: {n_lks:,} edges is too many for browser visualization.\")\n    print(\"Consider increasing MIN_WEIGHT or lowering MAX_EDGES/MAX_NODES.\")\n    print(\"Skipping export. Adjust params and re-run.\")\nelse:\n    meta = {\"clusterField\": \"community\", \"title\": \"Fuzz Archives\"}\n    out_path = _default_dist_dir() / \"cosmo_albums_community.json\"\n    CosmographAdapter.write(graph, out_path, meta=meta)\n    print()\n    print(\"Starting server — open in browser:\")\n    print(\"  http://127.0.0.1:8080/?data=/cosmo_albums_community.json\")\n    print()\n    print(\"Press Ctrl+C (or interrupt the kernel) to stop.\")\n    serve(port=8080)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}